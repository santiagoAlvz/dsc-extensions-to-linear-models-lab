{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Extensions to Linear Models - Lab"]},{"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to regularization!"]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","You will be able to:\n","\n","- Build a linear regression model with interactions and polynomial features \n","- Use feature selection to obtain the optimal subset of features in a dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Let's Get Started!\n","\n","Below we import all the necessary packages for this lab."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","from itertools import combinations\n","\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LinearRegression, Lasso\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures"]},{"cell_type":"markdown","metadata":{},"source":["Load the data."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","# Load data from CSV\n","df = pd.read_csv(\"ames.csv\")\n","# Subset columns\n","df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n","         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n","         'GarageArea', 'Fireplaces', 'SalePrice']]\n","\n","# Split the data into X and y\n","y = df['SalePrice']\n","X = df.drop(columns='SalePrice')\n","\n","# Split into train, test, and validation sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=0)"]},{"cell_type":"markdown","metadata":{},"source":["## Build a Baseline Housing Data Model"]},{"cell_type":"markdown","metadata":{},"source":["Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n","\n","Next steps:\n","\n","- Scale all the predictors using `StandardScaler`, then convert these scaled features back into DataFrame objects\n","- Build a baseline `LinearRegression` model using *scaled variables* as predictors and use the $R^2$ score to evaluate the model "]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>Fireplaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.114710</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.639316</td>\n","      <td>-0.804789</td>\n","      <td>1.261552</td>\n","      <td>0.499114</td>\n","      <td>0.250689</td>\n","      <td>0.327629</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.176719</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>0.838208</td>\n","      <td>0.641608</td>\n","      <td>-0.808132</td>\n","      <td>-0.247249</td>\n","      <td>-0.365525</td>\n","      <td>0.079146</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.246336</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.012560</td>\n","      <td>-0.329000</td>\n","      <td>-0.808132</td>\n","      <td>-0.944766</td>\n","      <td>-0.981739</td>\n","      <td>-1.105931</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.378617</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.339045</td>\n","      <td>-0.609036</td>\n","      <td>-0.808132</td>\n","      <td>-1.146010</td>\n","      <td>-0.981739</td>\n","      <td>-1.134602</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010898</td>\n","      <td>-1.563603</td>\n","      <td>1.304613</td>\n","      <td>-2.531499</td>\n","      <td>-1.315922</td>\n","      <td>0.550523</td>\n","      <td>-0.481708</td>\n","      <td>0.250689</td>\n","      <td>-2.281450</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>816</th>\n","      <td>-0.532331</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.510628</td>\n","      <td>-0.897228</td>\n","      <td>-0.808132</td>\n","      <td>-1.353116</td>\n","      <td>-2.214167</td>\n","      <td>-0.274466</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>817</th>\n","      <td>-0.309245</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>0.514106</td>\n","      <td>0.315353</td>\n","      <td>-0.808132</td>\n","      <td>-0.481708</td>\n","      <td>-0.365525</td>\n","      <td>0.088703</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>0.119419</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>-0.513011</td>\n","      <td>-0.899947</td>\n","      <td>1.684999</td>\n","      <td>0.796096</td>\n","      <td>0.866903</td>\n","      <td>-0.207566</td>\n","      <td>0.588023</td>\n","    </tr>\n","    <tr>\n","      <th>819</th>\n","      <td>-0.002718</td>\n","      <td>-0.099842</td>\n","      <td>1.304613</td>\n","      <td>-0.889542</td>\n","      <td>-1.329516</td>\n","      <td>0.783758</td>\n","      <td>-0.290233</td>\n","      <td>-0.365525</td>\n","      <td>-0.852668</td>\n","      <td>-0.994820</td>\n","    </tr>\n","    <tr>\n","      <th>820</th>\n","      <td>0.086287</td>\n","      <td>-0.099842</td>\n","      <td>0.397681</td>\n","      <td>0.433080</td>\n","      <td>0.179414</td>\n","      <td>-0.808132</td>\n","      <td>-0.579400</td>\n","      <td>-0.365525</td>\n","      <td>-0.675863</td>\n","      <td>2.170867</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>821 rows × 10 columns</p>\n","</div>"],"text/plain":["      LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0   -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1   -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2   -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3   -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4   -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","..        ...          ...          ...          ...       ...       ...   \n","816 -0.532331    -0.099842    -0.509252    -0.510628 -0.897228 -0.808132   \n","817 -0.309245    -0.099842    -0.509252     0.514106  0.315353 -0.808132   \n","818  0.119419     0.632038    -0.509252    -0.513011 -0.899947  1.684999   \n","819 -0.002718    -0.099842     1.304613    -0.889542 -1.329516  0.783758   \n","820  0.086287    -0.099842     0.397681     0.433080  0.179414 -0.808132   \n","\n","     GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  \n","0     0.499114      0.250689    0.327629   -0.994820  \n","1    -0.247249     -0.365525    0.079146   -0.994820  \n","2    -0.944766     -0.981739   -1.105931   -0.994820  \n","3    -1.146010     -0.981739   -1.134602    0.588023  \n","4    -0.481708      0.250689   -2.281450   -0.994820  \n","..         ...           ...         ...         ...  \n","816  -1.353116     -2.214167   -0.274466    0.588023  \n","817  -0.481708     -0.365525    0.088703   -0.994820  \n","818   0.796096      0.866903   -0.207566    0.588023  \n","819  -0.290233     -0.365525   -0.852668   -0.994820  \n","820  -0.579400     -0.365525   -0.675863    2.170867  \n","\n","[821 rows x 10 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Scale X_train and X_val using StandardScaler\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_val_scaled = scaler.transform(X_val)\n","\n","# Ensure X_train and X_val are scaled DataFrames\n","# (hint: you can set the columns using X.columns)\n","X_train = pd.DataFrame(X_train_scaled, columns=X.columns)\n","X_val = pd.DataFrame(X_val_scaled, columns=X.columns)\n","\n","X_train"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["(0.7868344817421309, 0.6375622643038104)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Create a LinearRegression model and fit it on scaled training data\n","linreg = LinearRegression()\n","linreg.fit(X_train, y_train)\n","\n","# Calculate a baseline r-squared score on training data\n","linreg.score(X_train, y_train), linreg.score(X_val, y_val)"]},{"cell_type":"markdown","metadata":{},"source":["## Add Interactions\n","\n","Instead of adding all possible interaction terms, let's try a custom technique. We are only going to add the interaction terms that increase the $R^2$ score as much as possible. Specifically we are going to look for the 7 interaction terms that each cause the most increase in the coefficient of determination.\n","\n","### Find the Best Interactions\n","\n","Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Create a data structure that stores the pair of columns used as well as the $R^2$ score for each combination.\n","\n","***Hint:*** We have imported the `combinations` function from `itertools` for you ([documentation here](https://docs.python.org/3/library/itertools.html#itertools.combinations)). Try applying this to the columns of `X_train` to find all of the possible pairs.\n","\n","Print the 7 interactions that result in the highest $R^2$ scores."]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/plain":["[(('1stFlrSF', 'Fireplaces'), -1426379.252578415),\n"," (('TotalBsmtSF', 'Fireplaces'), -1532661.4045867252),\n"," (('GarageArea', 'Fireplaces'), -1674034.5560282203),\n"," (('OverallQual', 'TotRmsAbvGrd'), -1734068.2188583324),\n"," (('TotRmsAbvGrd', 'Fireplaces'), -1752987.974196044),\n"," (('GrLivArea', 'Fireplaces'), -1837952.886961307),\n"," (('OverallQual', 'Fireplaces'), -1883381.2955321842)]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Set up data structure\n","interactions = []\n","\n","# Find combinations of columns and loop over them\n","column_sets = list(combinations(X.columns, 2))\n","\n","for (c1, c2) in column_sets:\n","    # Make copies of X_train and X_val\n","    train_set = X_train.copy()\n","    test_set = X_test.copy()\n","    \n","    # Add interaction term to data\n","    train_set['interaction'] = train_set[c1] * train_set[c2]\n","    test_set['interaction'] = test_set[c1] * test_set[c2]\n","    \n","    # Find r-squared score (fit on training data, evaluate on validation data)\n","    score = LinearRegression().fit(train_set, y_train).score(test_set, y_test)\n","    \n","    # Append to data structure\n","    interactions.append(((c1, c2), score))\n","    \n","    \n","# Sort and subset the data structure to find the top 7\n","top_interactions = sorted(interactions, key=lambda record: record[1], reverse=True)[:7]\n","top_interactions"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Interactions\n","\n","Write code to include the 7 most important interactions in `X_train` and `X_val` by adding 7 columns. Use the naming convention `\"col1_col2\"`, where `col1` and `col2` are the two columns in the interaction."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>TotalBsmtSF</th>\n","      <th>1stFlrSF</th>\n","      <th>2ndFlrSF</th>\n","      <th>GrLivArea</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>Fireplaces</th>\n","      <th>1stFlrSF_Fireplaces</th>\n","      <th>TotalBsmtSF_Fireplaces</th>\n","      <th>GarageArea_Fireplaces</th>\n","      <th>OverallQual_TotRmsAbvGrd</th>\n","      <th>TotRmsAbvGrd_Fireplaces</th>\n","      <th>GrLivArea_Fireplaces</th>\n","      <th>OverallQual_Fireplaces</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.114710</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.639316</td>\n","      <td>-0.804789</td>\n","      <td>1.261552</td>\n","      <td>0.499114</td>\n","      <td>0.250689</td>\n","      <td>0.327629</td>\n","      <td>-0.994820</td>\n","      <td>0.800620</td>\n","      <td>0.636004</td>\n","      <td>-0.325932</td>\n","      <td>-0.025029</td>\n","      <td>-0.249390</td>\n","      <td>-0.496529</td>\n","      <td>0.099325</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.176719</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>0.838208</td>\n","      <td>0.641608</td>\n","      <td>-0.808132</td>\n","      <td>-0.247249</td>\n","      <td>-0.365525</td>\n","      <td>0.079146</td>\n","      <td>-0.994820</td>\n","      <td>-0.638285</td>\n","      <td>-0.833866</td>\n","      <td>-0.078736</td>\n","      <td>-0.231026</td>\n","      <td>0.363632</td>\n","      <td>0.245968</td>\n","      <td>-0.628764</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.246336</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.012560</td>\n","      <td>-0.329000</td>\n","      <td>-0.808132</td>\n","      <td>-0.944766</td>\n","      <td>-0.981739</td>\n","      <td>-1.105931</td>\n","      <td>-0.994820</td>\n","      <td>0.327296</td>\n","      <td>0.012495</td>\n","      <td>1.100202</td>\n","      <td>0.816535</td>\n","      <td>0.976654</td>\n","      <td>0.939872</td>\n","      <td>0.827414</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.378617</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.339045</td>\n","      <td>-0.609036</td>\n","      <td>-0.808132</td>\n","      <td>-1.146010</td>\n","      <td>-0.981739</td>\n","      <td>-1.134602</td>\n","      <td>0.588023</td>\n","      <td>-0.358127</td>\n","      <td>-0.199366</td>\n","      <td>-0.667173</td>\n","      <td>0.816535</td>\n","      <td>-0.577286</td>\n","      <td>-0.673881</td>\n","      <td>-0.489072</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010898</td>\n","      <td>-1.563603</td>\n","      <td>1.304613</td>\n","      <td>-2.531499</td>\n","      <td>-1.315922</td>\n","      <td>0.550523</td>\n","      <td>-0.481708</td>\n","      <td>0.250689</td>\n","      <td>-2.281450</td>\n","      <td>-0.994820</td>\n","      <td>1.309105</td>\n","      <td>2.518386</td>\n","      <td>2.269632</td>\n","      <td>-0.391978</td>\n","      <td>-0.249390</td>\n","      <td>0.479213</td>\n","      <td>1.555503</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>816</th>\n","      <td>-0.532331</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>-0.510628</td>\n","      <td>-0.897228</td>\n","      <td>-0.808132</td>\n","      <td>-1.353116</td>\n","      <td>-2.214167</td>\n","      <td>-0.274466</td>\n","      <td>0.588023</td>\n","      <td>-0.527591</td>\n","      <td>-0.300261</td>\n","      <td>-0.161392</td>\n","      <td>0.221068</td>\n","      <td>-1.301982</td>\n","      <td>-0.795664</td>\n","      <td>-0.058710</td>\n","    </tr>\n","    <tr>\n","      <th>817</th>\n","      <td>-0.309245</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>0.514106</td>\n","      <td>0.315353</td>\n","      <td>-0.808132</td>\n","      <td>-0.481708</td>\n","      <td>-0.365525</td>\n","      <td>0.088703</td>\n","      <td>-0.994820</td>\n","      <td>-0.313720</td>\n","      <td>-0.511443</td>\n","      <td>-0.088243</td>\n","      <td>0.036495</td>\n","      <td>0.363632</td>\n","      <td>0.479213</td>\n","      <td>0.099325</td>\n","    </tr>\n","    <tr>\n","      <th>818</th>\n","      <td>0.119419</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>-0.513011</td>\n","      <td>-0.899947</td>\n","      <td>1.684999</td>\n","      <td>0.796096</td>\n","      <td>0.866903</td>\n","      <td>-0.207566</td>\n","      <td>0.588023</td>\n","      <td>-0.529190</td>\n","      <td>-0.301663</td>\n","      <td>-0.122054</td>\n","      <td>0.547915</td>\n","      <td>0.509759</td>\n","      <td>0.468123</td>\n","      <td>0.371653</td>\n","    </tr>\n","    <tr>\n","      <th>819</th>\n","      <td>-0.002718</td>\n","      <td>-0.099842</td>\n","      <td>1.304613</td>\n","      <td>-0.889542</td>\n","      <td>-1.329516</td>\n","      <td>0.783758</td>\n","      <td>-0.290233</td>\n","      <td>-0.365525</td>\n","      <td>-0.852668</td>\n","      <td>-0.994820</td>\n","      <td>1.322629</td>\n","      <td>0.884934</td>\n","      <td>0.848252</td>\n","      <td>0.036495</td>\n","      <td>0.363632</td>\n","      <td>0.288730</td>\n","      <td>0.099325</td>\n","    </tr>\n","    <tr>\n","      <th>820</th>\n","      <td>0.086287</td>\n","      <td>-0.099842</td>\n","      <td>0.397681</td>\n","      <td>0.433080</td>\n","      <td>0.179414</td>\n","      <td>-0.808132</td>\n","      <td>-0.579400</td>\n","      <td>-0.365525</td>\n","      <td>-0.675863</td>\n","      <td>2.170867</td>\n","      <td>0.389483</td>\n","      <td>0.940160</td>\n","      <td>-1.467208</td>\n","      <td>0.036495</td>\n","      <td>-0.793507</td>\n","      <td>-1.257800</td>\n","      <td>-0.216744</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>821 rows × 17 columns</p>\n","</div>"],"text/plain":["      LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n","0   -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n","1   -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n","2   -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n","3   -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n","4   -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n","..        ...          ...          ...          ...       ...       ...   \n","816 -0.532331    -0.099842    -0.509252    -0.510628 -0.897228 -0.808132   \n","817 -0.309245    -0.099842    -0.509252     0.514106  0.315353 -0.808132   \n","818  0.119419     0.632038    -0.509252    -0.513011 -0.899947  1.684999   \n","819 -0.002718    -0.099842     1.304613    -0.889542 -1.329516  0.783758   \n","820  0.086287    -0.099842     0.397681     0.433080  0.179414 -0.808132   \n","\n","     GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  1stFlrSF_Fireplaces  \\\n","0     0.499114      0.250689    0.327629   -0.994820             0.800620   \n","1    -0.247249     -0.365525    0.079146   -0.994820            -0.638285   \n","2    -0.944766     -0.981739   -1.105931   -0.994820             0.327296   \n","3    -1.146010     -0.981739   -1.134602    0.588023            -0.358127   \n","4    -0.481708      0.250689   -2.281450   -0.994820             1.309105   \n","..         ...           ...         ...         ...                  ...   \n","816  -1.353116     -2.214167   -0.274466    0.588023            -0.527591   \n","817  -0.481708     -0.365525    0.088703   -0.994820            -0.313720   \n","818   0.796096      0.866903   -0.207566    0.588023            -0.529190   \n","819  -0.290233     -0.365525   -0.852668   -0.994820             1.322629   \n","820  -0.579400     -0.365525   -0.675863    2.170867             0.389483   \n","\n","     TotalBsmtSF_Fireplaces  GarageArea_Fireplaces  OverallQual_TotRmsAbvGrd  \\\n","0                  0.636004              -0.325932                 -0.025029   \n","1                 -0.833866              -0.078736                 -0.231026   \n","2                  0.012495               1.100202                  0.816535   \n","3                 -0.199366              -0.667173                  0.816535   \n","4                  2.518386               2.269632                 -0.391978   \n","..                      ...                    ...                       ...   \n","816               -0.300261              -0.161392                  0.221068   \n","817               -0.511443              -0.088243                  0.036495   \n","818               -0.301663              -0.122054                  0.547915   \n","819                0.884934               0.848252                  0.036495   \n","820                0.940160              -1.467208                  0.036495   \n","\n","     TotRmsAbvGrd_Fireplaces  GrLivArea_Fireplaces  OverallQual_Fireplaces  \n","0                  -0.249390             -0.496529                0.099325  \n","1                   0.363632              0.245968               -0.628764  \n","2                   0.976654              0.939872                0.827414  \n","3                  -0.577286             -0.673881               -0.489072  \n","4                  -0.249390              0.479213                1.555503  \n","..                       ...                   ...                     ...  \n","816                -1.301982             -0.795664               -0.058710  \n","817                 0.363632              0.479213                0.099325  \n","818                 0.509759              0.468123                0.371653  \n","819                 0.363632              0.288730                0.099325  \n","820                -0.793507             -1.257800               -0.216744  \n","\n","[821 rows x 17 columns]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Loop over top 7 interactions\n","for record in top_interactions:\n","\n","    # Extract column names from data structure\n","    c1, c2 = record[0]\n","\n","    # Construct new column name\n","    col_name = c1 + '_' + c2\n","    \n","    # Add new column to X_train and X_val\n","    X_train[col_name] = X_train[c1] * X_train[c2]\n","    X_val[col_name] = X_val[c1] * X_val[c2]\n","\n","X_train"]},{"cell_type":"markdown","metadata":{},"source":["## Add Polynomials\n","\n","Now let's repeat that process for adding polynomial terms.\n","\n","### Find the Best Polynomials\n","\n","Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of degree 4 with `PolynomialFeatures`, the particular column is raised to the power of 2 and 3 as well in other terms.\n","\n","We only want to include \"pure\" polynomials, so make sure no interactions are included.\n","\n","Once again you should make a data structure that contains the values you have tested. We recommend a list of tuples of the form:\n","\n","`(col_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["[('GrLivArea', 4, 0.840566487625741),\n"," ('GarageArea_Fireplaces', 3, 0.8378978005115225),\n"," ('TotRmsAbvGrd_Fireplaces', 4, 0.836631969861492),\n"," ('1stFlrSF', 2, 0.6276363368875173),\n"," ('GrLivArea', 3, 0.6200292893882771),\n"," ('TotalBsmtSF', 2, 0.5754934763044448),\n"," ('TotRmsAbvGrd_Fireplaces', 3, 0.5645798507606035)]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","\n","# Set up data structure\n","polynomials = []\n","\n","# Loop over all columns\n","for column in X_train.columns:\n","\n","    # Loop over degrees 2, 3, 4\n","    for degree in [2, 3, 4]:\n","        \n","        # Make a copy of X_train and X_val\n","        features_train = X_train.copy()\n","        features_val = X_val.copy()\n","    \n","        # Instantiate PolynomialFeatures with relevant degree\n","        poly = PolynomialFeatures(degree)\n","        \n","        # Fit polynomial to column and transform column\n","        # Hint: use the notation df[[column_name]] to get the right shape\n","        # Hint: convert the result to a DataFrame\n","        transformed_train = pd.DataFrame(poly.fit_transform(features_train[[column]]))\n","        transformed_val = pd.DataFrame(poly.fit_transform(features_val[[column]]))\n","\n","        # Add polynomial to data\n","        # Hint: use pd.concat since you're combining two DataFrames\n","        # Hint: drop the column before combining so it doesn't appear twice\n","        features_train = pd.concat([features_train.drop(column, axis=1), transformed_train], axis=1)\n","        features_val = pd.concat([features_val.drop(column, axis=1), transformed_val], axis=1)\n","    \n","        # Find r-squared score on validation\n","        score = LinearRegression().fit(features_train, y_train).score(features_val, y_val)\n","    \n","        # Append to data structure\n","        polynomials.append(((column, degree, score)))\n","\n","# Sort and subset the data structure to find the top 7\n","top_polynomials = sorted(polynomials, key=lambda p: p[-1], reverse=True)[:7]\n","top_polynomials\n"]},{"cell_type":"markdown","metadata":{},"source":["### Add the Best Polynomials\n","\n","If there are duplicate column values in the results above, don't add multiple of them to the model, to avoid creating duplicate columns. (For example, if column `A` appeared in your list as both a 2nd and 3rd degree polynomial, adding both would result in `A` squared being added to the features twice.) Just add in the polynomial that results in the highest R-Squared."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# Your code here\n","top_polynomials = pd.DataFrame(top_polynomials, columns=[\"Column\", \"Degree\", \"R^2\"])\n","\n","# Drop duplicate columns based on Column name\n","top_polynomials.drop_duplicates(subset=\"Column\", inplace=True)\n","\n","# Loop over remaining results\n","for (col, degree, _) in top_polynomials.values:\n","    #Create polynomimal terms\n","    poly = PolynomialFeatures(degree, include_bias=False)\n","    train_poly = pd.DataFrame(poly.fit_transform(X_train[[col]]),\n","                              columns=poly.get_feature_names([col]))\n","    val_poly = pd.DataFrame(poly.transform(X_val[[col]]),\n","                              columns=poly.get_feature_names([col]))\n","    \n","    #Concat back to original\n","    X_train = pd.concat([X_train.drop(col, axis=1), train_poly], axis=1)\n","    X_val = pd.concat([X_val.drop(col, axis=1), val_poly], axis=1)\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>2ndFlrSF</th>\n","      <th>TotRmsAbvGrd</th>\n","      <th>GarageArea</th>\n","      <th>Fireplaces</th>\n","      <th>1stFlrSF_Fireplaces</th>\n","      <th>TotalBsmtSF_Fireplaces</th>\n","      <th>OverallQual_TotRmsAbvGrd</th>\n","      <th>...</th>\n","      <th>GarageArea_Fireplaces^2</th>\n","      <th>GarageArea_Fireplaces^3</th>\n","      <th>TotRmsAbvGrd_Fireplaces</th>\n","      <th>TotRmsAbvGrd_Fireplaces^2</th>\n","      <th>TotRmsAbvGrd_Fireplaces^3</th>\n","      <th>TotRmsAbvGrd_Fireplaces^4</th>\n","      <th>1stFlrSF</th>\n","      <th>1stFlrSF^2</th>\n","      <th>TotalBsmtSF</th>\n","      <th>TotalBsmtSF^2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.114710</td>\n","      <td>-0.099842</td>\n","      <td>-0.509252</td>\n","      <td>1.261552</td>\n","      <td>0.250689</td>\n","      <td>0.327629</td>\n","      <td>-0.994820</td>\n","      <td>0.800620</td>\n","      <td>0.636004</td>\n","      <td>-0.025029</td>\n","      <td>...</td>\n","      <td>0.106232</td>\n","      <td>-0.034624</td>\n","      <td>-0.249390</td>\n","      <td>0.062195</td>\n","      <td>-0.015511</td>\n","      <td>0.003868</td>\n","      <td>-0.804789</td>\n","      <td>0.647685</td>\n","      <td>-0.639316</td>\n","      <td>0.408725</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.176719</td>\n","      <td>0.632038</td>\n","      <td>-0.509252</td>\n","      <td>-0.808132</td>\n","      <td>-0.365525</td>\n","      <td>0.079146</td>\n","      <td>-0.994820</td>\n","      <td>-0.638285</td>\n","      <td>-0.833866</td>\n","      <td>-0.231026</td>\n","      <td>...</td>\n","      <td>0.006199</td>\n","      <td>-0.000488</td>\n","      <td>0.363632</td>\n","      <td>0.132228</td>\n","      <td>0.048082</td>\n","      <td>0.017484</td>\n","      <td>0.641608</td>\n","      <td>0.411661</td>\n","      <td>0.838208</td>\n","      <td>0.702592</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.246336</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.808132</td>\n","      <td>-0.981739</td>\n","      <td>-1.105931</td>\n","      <td>-0.994820</td>\n","      <td>0.327296</td>\n","      <td>0.012495</td>\n","      <td>0.816535</td>\n","      <td>...</td>\n","      <td>1.210445</td>\n","      <td>1.331733</td>\n","      <td>0.976654</td>\n","      <td>0.953852</td>\n","      <td>0.931583</td>\n","      <td>0.909834</td>\n","      <td>-0.329000</td>\n","      <td>0.108241</td>\n","      <td>-0.012560</td>\n","      <td>0.000158</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.378617</td>\n","      <td>-0.831723</td>\n","      <td>1.304613</td>\n","      <td>-0.808132</td>\n","      <td>-0.981739</td>\n","      <td>-1.134602</td>\n","      <td>0.588023</td>\n","      <td>-0.358127</td>\n","      <td>-0.199366</td>\n","      <td>0.816535</td>\n","      <td>...</td>\n","      <td>0.445119</td>\n","      <td>-0.296971</td>\n","      <td>-0.577286</td>\n","      <td>0.333259</td>\n","      <td>-0.192385</td>\n","      <td>0.111061</td>\n","      <td>-0.609036</td>\n","      <td>0.370925</td>\n","      <td>-0.339045</td>\n","      <td>0.114951</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.010898</td>\n","      <td>-1.563603</td>\n","      <td>1.304613</td>\n","      <td>0.550523</td>\n","      <td>0.250689</td>\n","      <td>-2.281450</td>\n","      <td>-0.994820</td>\n","      <td>1.309105</td>\n","      <td>2.518386</td>\n","      <td>-0.391978</td>\n","      <td>...</td>\n","      <td>5.151230</td>\n","      <td>11.691396</td>\n","      <td>-0.249390</td>\n","      <td>0.062195</td>\n","      <td>-0.015511</td>\n","      <td>0.003868</td>\n","      <td>-1.315922</td>\n","      <td>1.731650</td>\n","      <td>-2.531499</td>\n","      <td>6.408489</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 27 columns</p>\n","</div>"],"text/plain":["    LotArea  OverallQual  OverallCond  2ndFlrSF  TotRmsAbvGrd  GarageArea  \\\n","0 -0.114710    -0.099842    -0.509252  1.261552      0.250689    0.327629   \n","1 -0.176719     0.632038    -0.509252 -0.808132     -0.365525    0.079146   \n","2 -0.246336    -0.831723     1.304613 -0.808132     -0.981739   -1.105931   \n","3 -0.378617    -0.831723     1.304613 -0.808132     -0.981739   -1.134602   \n","4 -0.010898    -1.563603     1.304613  0.550523      0.250689   -2.281450   \n","\n","   Fireplaces  1stFlrSF_Fireplaces  TotalBsmtSF_Fireplaces  \\\n","0   -0.994820             0.800620                0.636004   \n","1   -0.994820            -0.638285               -0.833866   \n","2   -0.994820             0.327296                0.012495   \n","3    0.588023            -0.358127               -0.199366   \n","4   -0.994820             1.309105                2.518386   \n","\n","   OverallQual_TotRmsAbvGrd  ...  GarageArea_Fireplaces^2  \\\n","0                 -0.025029  ...                 0.106232   \n","1                 -0.231026  ...                 0.006199   \n","2                  0.816535  ...                 1.210445   \n","3                  0.816535  ...                 0.445119   \n","4                 -0.391978  ...                 5.151230   \n","\n","   GarageArea_Fireplaces^3  TotRmsAbvGrd_Fireplaces  \\\n","0                -0.034624                -0.249390   \n","1                -0.000488                 0.363632   \n","2                 1.331733                 0.976654   \n","3                -0.296971                -0.577286   \n","4                11.691396                -0.249390   \n","\n","   TotRmsAbvGrd_Fireplaces^2  TotRmsAbvGrd_Fireplaces^3  \\\n","0                   0.062195                  -0.015511   \n","1                   0.132228                   0.048082   \n","2                   0.953852                   0.931583   \n","3                   0.333259                  -0.192385   \n","4                   0.062195                  -0.015511   \n","\n","   TotRmsAbvGrd_Fireplaces^4  1stFlrSF  1stFlrSF^2  TotalBsmtSF  TotalBsmtSF^2  \n","0                   0.003868 -0.804789    0.647685    -0.639316       0.408725  \n","1                   0.017484  0.641608    0.411661     0.838208       0.702592  \n","2                   0.909834 -0.329000    0.108241    -0.012560       0.000158  \n","3                   0.111061 -0.609036    0.370925    -0.339045       0.114951  \n","4                   0.003868 -1.315922    1.731650    -2.531499       6.408489  \n","\n","[5 rows x 27 columns]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["# Your code here\n","X_train.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Full Model R-Squared"]},{"cell_type":"markdown","metadata":{},"source":["Check out the $R^2$ of the full model with your interaction and polynomial terms added. Print this value for both the train and validation data."]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Set R²: 0.8491535501803753\n","Test Set R²: -1.6223683879867723\n"]}],"source":["# Your code here\n","linreg = LinearRegression()\n","linreg.fit(X_train, y_train)\n","\n","print(f'Training Set R²: {linreg.score(X_train, y_train)}')\n","print(f'Test Set R²: {linreg.score(X_val, y_val)}')"]},{"cell_type":"markdown","metadata":{},"source":["It looks like we may be overfitting some now. Let's try some feature selection techniques."]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selection\n","\n","First, test out `RFE` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)) with several different `n_features_to_select` values. For each value, print out the train and validation $R^2$ score and how many features remain."]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using 5 features\n","Train R^2: 0.761338610096933\n","Test R^2:  0.6145963635536846\n","\n","Using 10 features\n","Train R^2: 0.8265527369041241\n","Test R^2:  0.6763957022287043\n","\n","Using 15 features\n","Train R^2: 0.8366074146143467\n","Test R^2:  0.4228738183823503\n","\n","Using 20 features\n","Train R^2: 0.8392835025666003\n","Test R^2:  0.4723686248222603\n","\n"]}],"source":["# Your code here\n","for n in range(5, 21, 5):\n","    rfe = RFE(LinearRegression(), n_features_to_select=n)\n","    X_rfe_train = rfe.fit_transform(X_train, y_train)\n","    X_rfe_val = rfe.transform(X_val)\n","\n","    lr = LinearRegression()\n","    lr.fit(X_rfe_train, y_train)\n","\n","    print(f\"Using {n} features\")\n","    print(\"Train R^2:\", lr.score(X_rfe_train, y_train))\n","    print(\"Test R^2: \", lr.score(X_rfe_val, y_val))\n","    print()\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Now test out `Lasso` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)) with several different `alpha` values."]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["With an alpha of 0.0\n","Train R^2: 0.849153548639979\n","Test R^2:  -1.623268145910822\n","\n","With an alpha of 22500.0\n","Train R^2: 0.6435613302649067\n","Test R^2:  -0.5634119122095225\n","\n","With an alpha of 45000.0\n","Train R^2: 0.3421428613320793\n","Test R^2:  0.30591791786680145\n","\n","With an alpha of 67500.0\n","Train R^2: 0.1720176088022709\n","Test R^2:  -0.7967892024704473\n","\n","With an alpha of 90000.0\n","Train R^2: 0.1327045978806951\n","Test R^2:  -2.3842953940921348\n","\n"]}],"source":["# Your code here\n","\n","train_mse = []\n","test_mse = []\n","alphas = np.linspace(0, 90000, num=5)\n","\n","for alpha in alphas:\n","    lasso = Lasso(alpha=alpha)\n","    lasso.fit(X_train, y_train)\n","    \n","    print(f\"With an alpha of {alpha}\")\n","    print(\"Train R^2:\", lasso.score(X_train, y_train))\n","    print(\"Test R^2: \", lasso.score(X_val, y_val))\n","    print()\n"]},{"cell_type":"markdown","metadata":{},"source":["Compare the results. Which features would you choose to use?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Your written answer here\n","\n","# For an RFE model, I would use 10 features. For a Lasso model, the best alpha was about 45k. In this scenario I would use an RFE model"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluate Final Model on Test Data\n","\n","### Data Preparation\n","\n","At the start of this lab, we created `X_test` and `y_test`. Prepare `X_test` the same way that `X_train` and `X_val` have been prepared. This includes scaling, adding interactions, and adding polynomial terms."]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["# Your code here\n","X_test_scaled = scaler.transform(X_test)\n","X_test = pd.DataFrame(X_test_scaled, columns=X.columns)\n","\n","for int in top_interactions:\n","    c1, c2 = int[0]\n","    new_col_name = c1 + \"_\" + c2\n","    X_test[new_col_name] = X_test[c1] * X_test[c2]\n","\n","for (col, degree, _) in top_polynomials.values:\n","    poly = PolynomialFeatures(degree, include_bias=False)\n","    poly_test = pd.DataFrame(poly.fit_transform(X_test[[col]]),\n","                                        columns=poly.get_feature_names([col]))\n","    X_test = pd.concat([X_test.drop(col, axis=1), poly_test], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation"]},{"cell_type":"markdown","metadata":{},"source":["Using either `RFE` or `Lasso`, fit a model on the complete train + validation set, then find R-Squared and MSE values for the test set."]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["R-Squared: 0.7970742584094077\n","MSE: 1421557534.5172462\n"]}],"source":["# Your code here\n","final_model = Lasso(alpha=10000)\n","final_model.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n","\n","print(\"R-Squared:\", final_model.score(X_test, y_test))\n","print(\"MSE:\", mean_squared_error(y_test, final_model.predict(X_test)))"]},{"cell_type":"markdown","metadata":{},"source":["## Level Up Ideas (Optional)\n","\n","### Create a Lasso Path\n","\n","From this section, you know that when using `Lasso`, more parameters shrink to zero as your regularization parameter goes up. In scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n","\n","https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py\n","\n","### AIC and BIC for Subset Selection\n","\n","This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!\n","\n","https://xavierbourretsicotte.github.io/subset_selection.html"]},{"cell_type":"markdown","metadata":{},"source":["## Summary"]},{"cell_type":"markdown","metadata":{},"source":["Congratulations! You now know how to apply concepts of bias-variance tradeoff using extensions to linear models and feature selection."]}],"metadata":{"kernelspec":{"display_name":"learn-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":4}
